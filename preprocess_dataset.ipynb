{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2093285-1ed6-49af-9da3-249939f02a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n"
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "print(catboost.__version__)\n",
    "import re\n",
    "#import bamboolib as bam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "# ML Pkgs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,classification_report\n",
    "from sklearn.metrics import accuracy_score,make_scorer\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix,classification_report\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE,SMOTENC,SVMSMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52745b1-3726-4981-9aeb-ac10acd529d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(bam.titanic_csv)\n",
    "df = pd.read_csv(\"D:/Projects/cp_heartdetect_model/Dataset/train.csv\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(df.head())\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc99834",
   "metadata": {},
   "source": [
    "### Обработка колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.rename(columns=\n",
    "{'ID': 'id', \n",
    "'Пол': 'sex',\n",
    "'Семья': 'family_status',\n",
    "'Этнос': 'ethnos',\n",
    "'Национальность': 'nationality',\n",
    "'Религия': 'religion',\n",
    "'Образование': 'education',\n",
    "'Профессия': 'profession',\n",
    "'Вы работаете?': 'work_status',\n",
    "'Выход на пенсию': 'pension_age',\n",
    "'Прекращение работы по болезни': 'stop_working',\n",
    "'Сахарный диабет': 'diabetes',\n",
    "'Гепатит': 'hepatitis',\n",
    "'Онкология': 'oncology',\n",
    "'Хроническое заболевание легких': 'lung_disease',\n",
    "'Бронжиальная астма': 'bronchial_asthma',\n",
    "'Туберкулез легких ': 'tuberculosis',\n",
    "'ВИЧ/СПИД': 'HIV_AIDS',\n",
    "'Регулярный прим лекарственных средств': 'intake_medicines',\n",
    "'Травмы за год': 'injuries_per_year',\n",
    "'Переломы': 'fractures',\n",
    "'Статус Курения': 'smoke_status',\n",
    "'Возраст курения': 'smoking_age',\n",
    "'Сигарет в день': 'cigarettes_pd',\n",
    "'Пассивное курение': 'passive_smoke',\n",
    "'Частота пасс кур': 'pass_smoke_rate',\n",
    "'Алкоголь': 'alcohol_status',\n",
    "'Возраст алког': 'alcohol_age',\n",
    "'Время засыпания': 'sleep_start_time',\n",
    "'Время пробуждения': 'sleep_end_time',\n",
    "'Сон после обеда': 'sleep_daily',\n",
    "'Спорт, клубы': 'sport_status',\n",
    "'Религия,клубы': 'religion_status',\n",
    "'ID_y': 'id_y',\n",
    "'Артериальная гипертензия': 'arterial_hypertension',\n",
    "'ОНМК': 'insult_status',\n",
    "'Стенокардия, ИБС, инфаркт миокарда': 'infarction_status',\n",
    "'Сердечная недостаточность': 'heart_failure',\n",
    "'Прочие заболевания сердца': 'oheart_diseases',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c526bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.family_status.unique()\n",
    "# df_test.ethnos.unique()\n",
    "# df_test.nationality.unique()\n",
    "# df_test.religion.unique()\n",
    "# df_test.education.unique()\n",
    "# df_test.profession.unique()\n",
    "# df_test.work_status.unique()\n",
    "for col in df_test:\n",
    "    print(df_test[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c23f5e",
   "metadata": {},
   "source": [
    "# Приведение датасета к нормальному виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213fd8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty with 0\n",
    "#df_test = df_test.replace('', np.nan, regex=True)\n",
    "df_test = df_test.fillna(0)\n",
    "\n",
    "# sex 1-женщина, 0-мужчина\n",
    "df_test.replace({'sex': 'М'}, {'sex': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'sex': 'Ж'}, {'sex': '1'}, regex=True, inplace = True)\n",
    "\n",
    "# family_status: 1-в браке в настоящее время, 0-в разводе, 2-вдовец / вдова, 3-никогда не был(а) в браке, 4-гражданский брак / проживание с партнером, 5-раздельное проживание (официально не разведены)\n",
    "df_test.replace({'family_status': 'в браке в настоящее время'}, {'family_status': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'family_status': 'в разводе'}, {'family_status': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'family_status': 'вдовец / вдова'}, {'family_status': '2'}, inplace = True)\n",
    "df_test.replace({'family_status': 'никогда не был(а) в браке'}, {'family_status': '3'}, inplace = True)\n",
    "df_test.replace({'family_status': 'гражданский брак / проживание с партнером'}, {'family_status': '4'}, inplace = True)\n",
    "df_test.replace({'family_status': 'раздельное проживание (официально не разведены)'}, {'family_status': '5'}, inplace = True)\n",
    "\n",
    "# ethnos 1-европейская, 2-другая азиатская (Корея, Малайзия, Таиланд, Вьетнам, Казахстан, Киргизия, Туркмения, Узбекистан, Таджикистан)\n",
    "df_test.replace({'ethnos': 'европейская'}, {'ethnos': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'ethnos': 'другая азиатская (Корея, Малайзия, Таиланд, Вьетнам, Казахстан, Киргизия, Туркмения, Узбекистан, Таджикистан)'}, {'ethnos': '2'}, inplace = True)\n",
    "df_test.replace({'ethnos': 'прочее (любая иная этно-расовая группа, не представленная выше)'}, {'ethnos': '2'},  inplace = True)\n",
    "\n",
    "# nationality:\n",
    "# 1-'Русские' 2-'Азербайджанцы' 3-'Татары' 4-'Немцы' 5-'Эстонцы'\n",
    "# 0-'Другие национальности' 6-'Молдаване' 7-'Украинцы' 8-'Чуваши' 9-'Мордва'\n",
    "# 10-'Киргизы' 11-'Казахи' 12-'Армяне' 13-'Белорусы' 14-'Таджики' 15-'Башкиры' 16-'Евреи'\n",
    "# 17-'Буряты'\n",
    "df_test.replace({'nationality': 'Другие национальности'}, {'nationality': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Русские'}, {'nationality': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Азербайджанцы'}, {'nationality': '2'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Татары'}, {'nationality': '3'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Немцы'}, {'nationality': '4'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Эстонцы'}, {'nationality': '5'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Молдаване'}, {'nationality': '6'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Украинцы'}, {'nationality': '7'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Чуваши'}, {'nationality': '8'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Мордва'}, {'nationality': '9'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Киргизы'}, {'nationality': '10'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Казахи'}, {'nationality': '11'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Армяне'}, {'nationality': '12'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Белорусы'}, {'nationality': '13'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Таджики'}, {'nationality': '14'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Башкиры'}, {'nationality': '15'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Евреи'}, {'nationality': '16'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Буряты'}, {'nationality': '17'}, regex=True, inplace = True)\n",
    "\n",
    "# religion: 1-'Христианство' 2-'Атеист / агностик' 3-'Ислам' 0-'Нет'\n",
    "df_test.replace({'religion': 'Нет'}, {'religion': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'religion': 'Христианство'}, {'religion': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'religion': 'Атеист / агностик'}, {'religion': '2'}, regex=True, inplace = True)\n",
    "df_test.replace({'religion': 'Ислам'}, {'religion': '3'}, regex=True, inplace = True)\n",
    "\n",
    "# education: 1-'3 - средняя школа / закон.среднее / выше среднего' 2-'5 - ВУЗ' 3-'2 - начальная школа' 4-'4 - профессиональное училище'\n",
    "df_test.replace({'education': '3 - средняя школа / закон.среднее / выше среднего'}, {'education': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'education': '5 - ВУЗ'}, {'education': '2'}, regex=True, inplace = True)\n",
    "df_test.replace({'education': '2 - начальная школа'}, {'education': '3'}, regex=True, inplace = True)\n",
    "df_test.replace({'education': '4 - профессиональное училище'}, {'education': '4'}, regex=True, inplace = True)\n",
    "\n",
    "# profession: 0-'низкоквалифицированные работники' 1-'дипломированные специалисты'\n",
    "# 2-'операторы и монтажники установок и машинного оборудования' 3-'служащие'\n",
    "# 4-'работники,  занятые в сфере обслуживания, торговые работники магазинов и рынков'\n",
    "# 5-'представители   законодат.   органов   власти,  высокопостав. долж.лица и менеджеры'\n",
    "# 6-'техники и младшие специалисты' 7-'ведение домашнего хозяйства'\n",
    "# 8-'квалифицированные работники сельского хозяйства и рыболовного'\n",
    "# 9-'ремесленники и представители других отраслей промышленности'\n",
    "# 10-'вооруженные силы'\n",
    "df_test.replace({'profession': 'низкоквалифицированные работники'}, {'profession': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'дипломированные специалисты'}, {'profession': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'операторы и монтажники установок и машинного оборудования'}, {'profession': '2'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'служащие'}, {'profession': '3'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'работники,  занятые в сфере обслуживания, торговые работники магазинов и рынков'}, {'profession': '4'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'представители   законодат.   органов   власти,  высокопостав. долж.лица и менеджеры'}, {'profession': '5'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'техники и младшие специалисты'}, {'profession': '6'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'ведение домашнего хозяйства'}, {'profession': '7'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'квалифицированные работники сельского хозяйства и рыболовного'}, {'profession': '8'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'ремесленники и представители других отраслей промышленности'}, {'profession': '9'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'вооруженные силы'}, {'profession': '10'}, regex=True, inplace = True)\n",
    "\n",
    "# smoke_status: 1-'Курит' 0-'Никогда не курил(а)' 2-'Бросил(а)'\n",
    "df_test.replace({'smoke_status': 'Курит'}, {'smoke_status': '1'}, inplace = True)\n",
    "df_test.replace({'smoke_status': 'Никогда не курил(а)'}, {'smoke_status': '0'},  inplace = True)\n",
    "df_test.replace({'smoke_status': 'Бросил(а)'}, {'smoke_status': '2'},  inplace = True)\n",
    "\n",
    "\n",
    "# pass_smoke_rate: 1-'1-2 раза в неделю' 2-'3-6 раз в неделю' 3-'не менее 1 раза в день' 4-'4 и более раз в день' 5-'2-3 раза в день'\n",
    "df_test.replace({'pass_smoke_rate': '1-2 раза в неделю'}, {'pass_smoke_rate': '1'}, inplace = True)\n",
    "df_test.replace({'pass_smoke_rate': '3-6 раз в неделю'}, {'pass_smoke_rate': '2'},  inplace = True)\n",
    "df_test.replace({'pass_smoke_rate': 'не менее 1 раза в день'}, {'pass_smoke_rate': '3'},  inplace = True)\n",
    "df_test.replace({'pass_smoke_rate': '4 и более раз в день'}, {'pass_smoke_rate': '4'},  inplace = True)\n",
    "df_test.replace({'pass_smoke_rate': '2-3 раза в день'}, {'pass_smoke_rate': '5'},  inplace = True)\n",
    "\n",
    "# alcohol_status, 1-'употребляю в настоящее время' 0-'никогда не употреблял' 2-'ранее употреблял'\n",
    "df_test.replace({'alcohol_status': 'употребляю в настоящее время'}, {'alcohol_status': '1'}, inplace = True)\n",
    "df_test.replace({'alcohol_status': 'никогда не употреблял'}, {'alcohol_status': '0'}, inplace = True)\n",
    "df_test.replace({'alcohol_status': 'ранее употреблял'}, {'alcohol_status': '2'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b242a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38ba3b",
   "metadata": {},
   "source": [
    "### Удаление ненужных колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fb45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop id and id_y, sleep_start_time, sleep_end_time\n",
    "columns_to_drop = ['id', 'id_y', 'sleep_start_time', 'sleep_end_time']\n",
    "df_test.drop(labels=columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_test:\n",
    "    print(df_test[col], ' - ', df_test[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee954f",
   "metadata": {},
   "source": [
    "### Нормализация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler() \n",
    "# scaled_values = scaler.fit_transform(df_test) \n",
    "# df_test.loc[:,:] = scaled_values\n",
    "\n",
    "# say df is the dataframe\n",
    "for c in df_test.columns:\n",
    "    if df_test[c].dtype == np.float:\n",
    "        df_test[c] = df_test[c].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()\n",
    "#df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36853dd0-451d-474f-a8c2-90aeaacfffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"processed.csv\", sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3df188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e1b82b",
   "metadata": {},
   "source": [
    "### Приведение типов к int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd329ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['sex'] = df_test['sex'].astype(int)\n",
    "df_test['family_status'] = df_test['family_status'].astype(int)\n",
    "df_test['ethnos'] = df_test['ethnos'].astype(int)\n",
    "df_test['nationality'] = df_test['nationality'].astype(int)\n",
    "df_test['religion'] = df_test['religion'].astype(int)\n",
    "df_test['education'] = df_test['education'].astype(int)\n",
    "df_test['profession'] = df_test['profession'].astype(int)\n",
    "df_test['smoke_status'] = df_test['smoke_status'].astype(int)\n",
    "df_test['pass_smoke_rate'] = df_test['pass_smoke_rate'].astype(int)\n",
    "df_test['alcohol_status'] = df_test['pass_smoke_rate'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fb412d",
   "metadata": {},
   "source": [
    "### Определение средних значений по предсказываемым лейблам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f641f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arterial_hypertension:  0    53.3\n",
      "1    46.7\n",
      "Name: arterial_hypertension, dtype: float64\n",
      "insult_status:  0    95.71\n",
      "1     4.29\n",
      "Name: insult_status, dtype: float64\n",
      "infarction_status:  0    87.75\n",
      "1    12.25\n",
      "Name: infarction_status, dtype: float64\n",
      "heart_failure:  0    89.95\n",
      "1    10.05\n",
      "Name: heart_failure, dtype: float64\n",
      "oheart_diseases:  0    90.99\n",
      "1     9.01\n",
      "Name: oheart_diseases, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"arterial_hypertension: \", round(df_test.arterial_hypertension.value_counts()*100/len(df_test),2))\n",
    "print(\"insult_status: \", round(df_test.insult_status.value_counts()*100/len(df_test),2))\n",
    "print(\"infarction_status: \", round(df_test.infarction_status.value_counts()*100/len(df_test),2))\n",
    "print(\"heart_failure: \", round(df_test.heart_failure.value_counts()*100/len(df_test),2))\n",
    "print(\"oheart_diseases: \", round(df_test.oheart_diseases.value_counts()*100/len(df_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71436fe2",
   "metadata": {},
   "source": [
    "### Формирование фреймов на основе предсказываемых лейблов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 'Артериальная гипертензия': 'arterial_hypertension',\n",
    "# 'ОНМК': 'insult_status',\n",
    "# 'Стенокардия, ИБС, инфаркт миокарда': 'infarction_status',\n",
    "# 'Сердечная недостаточность': 'heart_failure',\n",
    "# 'Прочие заболевания сердца': 'oheart_diseases',\n",
    "\n",
    "y1 = df_test[\"arterial_hypertension\"]\n",
    "y2 = df_test[\"insult_status\"]\n",
    "y3 = df_test[\"infarction_status\"]\n",
    "y4 = df_test[\"heart_failure\"]\n",
    "y5 = df_test[\"oheart_diseases\"]\n",
    "multiclass = ['arterial_hypertension','insult_status','infarction_status','heart_failure','oheart_diseases']\n",
    "y = df_test[multiclass]\n",
    "X1 = df_test.drop(multiclass, axis=1)\n",
    "X2 = df_test.drop(multiclass, axis=1)\n",
    "X3 = df_test.drop(multiclass, axis=1)\n",
    "X4 = df_test.drop(multiclass, axis=1)\n",
    "X5 = df_test.drop(multiclass, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c63e8",
   "metadata": {},
   "source": [
    "### SMOTE выравнивание несбалансированных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f99a3ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE1 : Counter({0: 509, 1: 446})\n",
      "After SMOTE1 : Counter({0: 509, 1: 509})\n",
      "Before SMOTE2 : Counter({0: 914, 1: 41})\n",
      "After SMOTE2 : Counter({0: 914, 1: 914})\n",
      "Before SMOTE3 : Counter({0: 838, 1: 117})\n",
      "After SMOTE3 : Counter({0: 838, 1: 838})\n",
      "Before SMOTE4 : Counter({0: 859, 1: 96})\n",
      "After SMOTE4 : Counter({0: 859, 1: 859})\n",
      "Before SMOTE5 : Counter({0: 869, 1: 86})\n",
      "After SMOTE5 : Counter({0: 869, 1: 869})\n"
     ]
    }
   ],
   "source": [
    "smote1 = SMOTE('auto',random_state=42)\n",
    "X_train1_smote,y_train1_smote = smote1.fit_resample(X1,y1)\n",
    "\n",
    "print(\"Before SMOTE1 :\", Counter(y1))\n",
    "print(\"After SMOTE1 :\", Counter(y_train1_smote))\n",
    "\n",
    "smote2 = SMOTE('auto',random_state=42)\n",
    "X_train2_smote,y_train2_smote = smote2.fit_resample(X2,y2)\n",
    "\n",
    "print(\"Before SMOTE2 :\", Counter(y2))\n",
    "print(\"After SMOTE2 :\", Counter(y_train2_smote))\n",
    "\n",
    "smote3 = SMOTE('auto',random_state=42)\n",
    "X_train3_smote,y_train3_smote = smote3.fit_resample(X3,y3)\n",
    "\n",
    "print(\"Before SMOTE3 :\", Counter(y3))\n",
    "print(\"After SMOTE3 :\", Counter(y_train3_smote))\n",
    "\n",
    "smote4 = SMOTE('auto',random_state=42)\n",
    "X_train4_smote,y_train4_smote = smote4.fit_resample(X4,y4)\n",
    "\n",
    "print(\"Before SMOTE4 :\", Counter(y4))\n",
    "print(\"After SMOTE4 :\", Counter(y_train4_smote))\n",
    "\n",
    "smote5 = SMOTE('auto',random_state=42)\n",
    "X_train5_smote,y_train5_smote = smote5.fit_resample(X5,y5)\n",
    "\n",
    "print(\"Before SMOTE5 :\", Counter(y5))\n",
    "print(\"After SMOTE5 :\", Counter(y_train5_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "426339a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train1_smote,y_train1_smote = X1,y1\n",
    "# X_train2_smote,y_train2_smote = X2,y2\n",
    "# X_train3_smote,y_train3_smote = X3,y3\n",
    "# X_train4_smote,y_train4_smote = X4,y4\n",
    "# X_train5_smote,y_train5_smote = X5,y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "20837fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение arterial_hypertension....\n",
      "\n",
      "fold 0 f1 0.673958338052202\n",
      "[[81 36]\n",
      " [47 91]]\n",
      "fold 1 f1 0.7450509869070919\n",
      "[[93 31]\n",
      " [34 97]]\n",
      "fold 2 f1 0.7204681081918934\n",
      "[[92 36]\n",
      " [35 91]]\n",
      "fold 3 f1 0.6919776119402985\n",
      "[[81 32]\n",
      " [46 95]]\n",
      "Mean f1 score for arterial_hypertension 0.7078637612728714\n"
     ]
    }
   ],
   "source": [
    "# 'arterial_hypertension','insult_status','infarction_status','heart_failure','oheart_diseases'\n",
    "\n",
    "categorical_features_indices=[0]\n",
    "\n",
    "######################################################################\n",
    "# arterial_hypertension\n",
    "print('Обучение arterial_hypertension....\\n')\n",
    "\n",
    "arterial_hypertension = CatBoostClassifier(verbose=False)\n",
    "params = {\n",
    "          'n_estimators': [100, 500, 1000],\n",
    "          'depth': [3, 4, 5, 6, 7],\n",
    "          'loss_function': ['MultiLogloss'],\n",
    "          'l2_leaf_reg': np.logspace(-20, -19, 3, 7),\n",
    "          'leaf_estimation_iterations': [10],\n",
    "          'logging_level':['Silent'],\n",
    "          'random_seed': [42]\n",
    "         }\n",
    "scorer = make_scorer(accuracy_score)\n",
    "clf_grid = GridSearchCV(estimator=arterial_hypertension, param_grid=params, scoring=scorer, cv=5)\n",
    "\n",
    "# arterial_hypertension = CatBoostClassifier(learning_rate=0.055, \n",
    "#                           n_estimators=1000, \n",
    "#                           subsample=0.075, \n",
    "#                           max_depth=3, \n",
    "#                           verbose=False,\n",
    "#                           l2_leaf_reg = 7,\n",
    "#                           bootstrap_type=\"Bernoulli\",\n",
    "#                           loss_function='MultiLogloss')\n",
    "#                           eval_metric='F1')\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4,shuffle=True,random_state=99)\n",
    "f1 = []\n",
    "\n",
    "for fold,(t_id,v_id) in enumerate(kf.split(X_train1_smote,y_train1_smote)):\n",
    "    tx = X_train1_smote.iloc[t_id]; ty = y_train1_smote.iloc[t_id]\n",
    "    vx = X_train1_smote.iloc[v_id]; vy = y_train1_smote.iloc[v_id]\n",
    "    arterial_hypertension.fit(tx,ty)        \n",
    "    val_y = arterial_hypertension.predict(vx)\n",
    "    \n",
    "    F1_score = f1_score(vy, val_y,average='weighted')\n",
    "    recall_score = score(vy, val_y)\n",
    "    f1.append(F1_score)\n",
    "\n",
    "    print(f\"fold {fold} f1 {F1_score}\")\n",
    "    print(confusion_matrix(val_y, vy))\n",
    "\n",
    "print(f\"Mean f1 score for arterial_hypertension {np.mean(f1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1e3d908",
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Only one of parameters ['verbose', 'logging_level', 'verbose_eval', 'silent'] should be set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-a1fc7f5a9475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1_smote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1_smote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbest_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_safe_split\u001b[1;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \"\"\"\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             raise ValueError(\"Precomputed kernels or affinity matrices have \"\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_is_pairwise\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[0mhas_pairwise_attribute\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_pairwise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[0mpairwise_attribute\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_pairwise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m     \u001b[0mpairwise_tag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pairwise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_pairwise_attribute\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\utils\\_tags.py\u001b[0m in \u001b[0;36m_safe_tags\u001b[1;34m(estimator, key)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_get_tags\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mtags_provider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"_get_tags()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_more_tags\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mtags_provider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"_more_tags()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_get_tags\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1755\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m         \u001b[0m_process_synonyms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1759\u001b[0m         \u001b[0mtags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'non_deterministic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'task_type'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'task_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'GPU'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_process_synonyms\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m     metric_period, verbose, logging_level = _process_verbose(\n\u001b[1;32m-> 1318\u001b[1;33m         metric_period, verbose, logging_level, verbose_eval, silent)\n\u001b[0m\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmetric_period\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_process_verbose\u001b[1;34m(metric_period, verbose, logging_level, verbose_eval, silent)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0mat_most_one\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclusive\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mexclusive\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclusive_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mat_most_one\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Only one of parameters {} should be set'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclusive_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: Only one of parameters ['verbose', 'logging_level', 'verbose_eval', 'silent'] should be set"
     ]
    }
   ],
   "source": [
    "clf_grid.fit(X_train1_smote, y_train1_smote)\n",
    "best_param = clf_grid.best_params_\n",
    "best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf34a8",
   "metadata": {},
   "source": [
    "### Обучение моделей для предсказания 'arterial_hypertension','insult_status','infarction_status','heart_failure','oheart_diseases'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "492ff6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение arterial_hypertension....\n",
      "\n",
      "fold 0 f1 0.6432330827067669\n",
      "[[44 23]\n",
      " [29 50]]\n",
      "fold 1 f1 0.6777041942604857\n",
      "[[47 21]\n",
      " [26 52]]\n",
      "fold 2 f1 0.7259759759759759\n",
      "[[52 19]\n",
      " [21 54]]\n",
      "fold 3 f1 0.6934880636604774\n",
      "[[58 29]\n",
      " [15 43]]\n",
      "fold 4 f1 0.7234014571661537\n",
      "[[49 16]\n",
      " [24 56]]\n",
      "fold 5 f1 0.7170798721730095\n",
      "[[50 19]\n",
      " [22 54]]\n",
      "fold 6 f1 0.6551724137931034\n",
      "[[47 25]\n",
      " [25 48]]\n",
      "Mean f1 score for arterial_hypertension 0.6908650085337102\n",
      "Обучение insult_status....\n",
      "\n",
      "fold 0 f1 0.9618298368298368\n",
      "[[125   4]\n",
      " [  6 127]]\n",
      "fold 1 f1 0.9655071150277589\n",
      "[[124   2]\n",
      " [  7 128]]\n",
      "fold 2 f1 0.9655071150277589\n",
      "[[124   2]\n",
      " [  7 128]]\n",
      "fold 3 f1 0.9731722005771457\n",
      "[[125   1]\n",
      " [  6 129]]\n",
      "fold 4 f1 0.9693459589209388\n",
      "[[125   3]\n",
      " [  5 128]]\n",
      "fold 5 f1 0.9655162289225486\n",
      "[[125   4]\n",
      " [  5 127]]\n",
      "fold 6 f1 0.957853168683115\n",
      "[[124   5]\n",
      " [  6 126]]\n",
      "Mean f1 score insult_status 0.9655330891413003\n",
      "Обучение infarction_status....\n",
      "\n",
      "fold 0 f1 0.9166608792277241\n",
      "[[109   9]\n",
      " [ 11 111]]\n",
      "fold 1 f1 0.8874042153915658\n",
      "[[103  10]\n",
      " [ 17 110]]\n",
      "fold 2 f1 0.89129677374399\n",
      "[[100   6]\n",
      " [ 20 114]]\n",
      "fold 3 f1 0.899483057736363\n",
      "[[104   8]\n",
      " [ 16 111]]\n",
      "fold 4 f1 0.9163179916317992\n",
      "[[110  10]\n",
      " [ 10 109]]\n",
      "fold 5 f1 0.895397489539749\n",
      "[[107  13]\n",
      " [ 12 107]]\n",
      "fold 6 f1 0.907859469591666\n",
      "[[112  15]\n",
      " [  7 105]]\n",
      "Mean f1 score infarction_status 0.9020599824089796\n",
      "Обучение heart_failure....\n",
      "\n",
      "fold 0 f1 0.8818776388773905\n",
      "[[103   9]\n",
      " [ 20 114]]\n",
      "fold 1 f1 0.9146327356853672\n",
      "[[113  11]\n",
      " [ 10 112]]\n",
      "fold 2 f1 0.9308383084988507\n",
      "[[111   5]\n",
      " [ 12 118]]\n",
      "fold 3 f1 0.8734272172099354\n",
      "[[105  13]\n",
      " [ 18 109]]\n",
      "fold 4 f1 0.946938775510204\n",
      "[[116   6]\n",
      " [  7 116]]\n",
      "fold 5 f1 0.9387755102040819\n",
      "[[115   8]\n",
      " [  7 115]]\n",
      "fold 6 f1 0.9224489795918367\n",
      "[[113  10]\n",
      " [  9 113]]\n",
      "Mean f1 score heart_failure 0.9155627379396668\n",
      "Обучение oheart_diseases....\n",
      "\n",
      "fold 0 f1 0.9156626506024096\n",
      "[[114  10]\n",
      " [ 11 114]]\n",
      "fold 1 f1 0.891566265060241\n",
      "[[111  14]\n",
      " [ 13 111]]\n",
      "fold 2 f1 0.9395151456026535\n",
      "[[116   7]\n",
      " [  8 117]]\n",
      "fold 3 f1 0.9233260109022862\n",
      "[[111   6]\n",
      " [ 13 118]]\n",
      "fold 4 f1 0.9193495934959349\n",
      "[[113   9]\n",
      " [ 11 115]]\n",
      "fold 5 f1 0.9071357634762223\n",
      "[[108   7]\n",
      " [ 16 117]]\n",
      "fold 6 f1 0.9111979166666666\n",
      "[[109   7]\n",
      " [ 15 117]]\n",
      "Mean f1 score oheart_diseases 0.9153933351152019\n"
     ]
    }
   ],
   "source": [
    "# 'arterial_hypertension','insult_status','infarction_status','heart_failure','oheart_diseases'\n",
    "\n",
    "categorical_features_indices=[0]\n",
    "\n",
    "######################################################################\n",
    "# arterial_hypertension\n",
    "print('Обучение arterial_hypertension....\\n')\n",
    "arterial_hypertension = CatBoostClassifier(learning_rate=0.055, \n",
    "                          n_estimators=1000, \n",
    "                          subsample=0.075, \n",
    "                          max_depth=5, \n",
    "                          verbose=False,\n",
    "                          l2_leaf_reg = 7,\n",
    "                          bootstrap_type=\"Bernoulli\",\n",
    "                          loss_function='MultiLogloss')\n",
    "                    #      eval_metric='F1')\n",
    "\n",
    "kf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\n",
    "f1 = []\n",
    "\n",
    "for fold,(t_id,v_id) in enumerate(kf.split(X_train1_smote,y_train1_smote)):\n",
    "    tx = X_train1_smote.iloc[t_id]; ty = y_train1_smote.iloc[t_id]\n",
    "    vx = X_train1_smote.iloc[v_id]; vy = y_train1_smote.iloc[v_id]\n",
    "    arterial_hypertension.fit(tx,ty)        \n",
    "    val_y = arterial_hypertension.predict(vx)\n",
    "    \n",
    "    F1_score = f1_score(vy, val_y,average='weighted')\n",
    "    recall_score = score(vy, val_y)\n",
    "    f1.append(F1_score)\n",
    "\n",
    "    print(f\"fold {fold} f1 {F1_score}\")\n",
    "    print(confusion_matrix(val_y, vy))\n",
    "\n",
    "print(f\"Mean f1 score for arterial_hypertension {np.mean(f1)}\")\n",
    "\n",
    "######################################################################\n",
    "# insult_status\n",
    "print('Обучение insult_status....\\n')\n",
    "\n",
    "insult_status = CatBoostClassifier(learning_rate=0.055, \n",
    "                          n_estimators=1000, \n",
    "                          subsample=0.075, \n",
    "                          max_depth=5, \n",
    "                          verbose=False,\n",
    "                          l2_leaf_reg = 7,\n",
    "                          bootstrap_type=\"Bernoulli\",\n",
    "                          #class_weights=[1, 1],\n",
    "                          loss_function='MultiLogloss')\n",
    "#                           eval_metric='F1')\n",
    "\n",
    "kf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\n",
    "f1 = []\n",
    "\n",
    "for fold,(t_id,v_id) in enumerate(kf.split(X_train2_smote,y_train2_smote)):\n",
    "    tx = X_train2_smote.iloc[t_id]; ty = y_train2_smote.iloc[t_id]\n",
    "    vx = X_train2_smote.iloc[v_id]; vy = y_train2_smote.iloc[v_id]\n",
    "    insult_status.fit(tx,ty)        \n",
    "    val_y = insult_status.predict(vx)\n",
    "    \n",
    "    F1_score = f1_score(vy, val_y,average='weighted')\n",
    "    f1.append(F1_score)\n",
    "\n",
    "    print(f\"fold {fold} f1 {F1_score}\")\n",
    "    print(confusion_matrix(val_y, vy))\n",
    "\n",
    "print(f\"Mean f1 score insult_status {np.mean(f1)}\")\n",
    "\n",
    "######################################################################\n",
    "# infarction_status\n",
    "print('Обучение infarction_status....\\n')\n",
    "\n",
    "infarction_status = CatBoostClassifier(learning_rate=0.055, \n",
    "                          n_estimators=1000, \n",
    "                          subsample=0.075, \n",
    "                          max_depth=5, \n",
    "                          verbose=False,\n",
    "                          l2_leaf_reg = 7,\n",
    "                          bootstrap_type=\"Bernoulli\",\n",
    "                          #class_weights=[1, 1],\n",
    "                          loss_function='MultiLogloss')\n",
    "#                           eval_metric='F1')\n",
    "\n",
    "kf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\n",
    "f1 = []\n",
    "\n",
    "for fold,(t_id,v_id) in enumerate(kf.split(X_train3_smote,y_train3_smote)):\n",
    "    tx = X_train3_smote.iloc[t_id]; ty = y_train3_smote.iloc[t_id]\n",
    "    vx = X_train3_smote.iloc[v_id]; vy = y_train3_smote.iloc[v_id]\n",
    "    infarction_status.fit(tx,ty)        \n",
    "    val_y = infarction_status.predict(vx)\n",
    "    \n",
    "    F1_score = f1_score(vy, val_y,average='weighted')\n",
    "    f1.append(F1_score)\n",
    "\n",
    "    print(f\"fold {fold} f1 {F1_score}\")\n",
    "    print(confusion_matrix(val_y, vy))\n",
    "\n",
    "print(f\"Mean f1 score infarction_status {np.mean(f1)}\")\n",
    "\n",
    "######################################################################\n",
    "# heart_failure\n",
    "print('Обучение heart_failure....\\n')\n",
    "\n",
    "heart_failure = CatBoostClassifier(learning_rate=0.055, \n",
    "                          n_estimators=1000, \n",
    "                          subsample=0.075, \n",
    "                          max_depth=5, \n",
    "                          verbose=False,\n",
    "                          l2_leaf_reg = 7,\n",
    "                          bootstrap_type=\"Bernoulli\",\n",
    "                          #class_weights=[1, 1],\n",
    "                          loss_function='MultiLogloss')\n",
    "#                           eval_metric='F1')\n",
    "\n",
    "kf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\n",
    "f1 = []\n",
    "\n",
    "for fold,(t_id,v_id) in enumerate(kf.split(X_train4_smote,y_train4_smote)):\n",
    "    tx = X_train4_smote.iloc[t_id]; ty = y_train4_smote.iloc[t_id]\n",
    "    vx = X_train4_smote.iloc[v_id]; vy = y_train4_smote.iloc[v_id]\n",
    "    heart_failure.fit(tx,ty)        \n",
    "    val_y = heart_failure.predict(vx)\n",
    "    \n",
    "    F1_score = f1_score(vy, val_y,average='weighted')\n",
    "    f1.append(F1_score)\n",
    "\n",
    "    print(f\"fold {fold} f1 {F1_score}\")\n",
    "    print(confusion_matrix(val_y, vy))\n",
    "\n",
    "print(f\"Mean f1 score heart_failure {np.mean(f1)}\")\n",
    "\n",
    "######################################################################\n",
    "# oheart_diseases\n",
    "print('Обучение oheart_diseases....\\n')\n",
    "\n",
    "oheart_diseases = CatBoostClassifier(learning_rate=0.055, \n",
    "                          n_estimators=1000, \n",
    "                          subsample=0.075, \n",
    "                          max_depth=5, \n",
    "                          verbose=False,\n",
    "                          l2_leaf_reg = 7,\n",
    "                          bootstrap_type=\"Bernoulli\",\n",
    "                          #class_weights=[1, 1],\n",
    "                          loss_function='MultiLogloss')\n",
    "#                           eval_metric='F1')\n",
    "\n",
    "kf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\n",
    "f1 = []\n",
    "\n",
    "for fold,(t_id,v_id) in enumerate(kf.split(X_train5_smote,y_train5_smote)):\n",
    "    tx = X_train5_smote.iloc[t_id]; ty = y_train5_smote.iloc[t_id]\n",
    "    vx = X_train5_smote.iloc[v_id]; vy = y_train5_smote.iloc[v_id]\n",
    "    oheart_diseases.fit(tx,ty)        \n",
    "    val_y = oheart_diseases.predict(vx)\n",
    "    \n",
    "    F1_score = f1_score(vy, val_y,average='weighted')\n",
    "    f1.append(F1_score)\n",
    "\n",
    "    print(f\"fold {fold} f1 {F1_score}\")\n",
    "    print(confusion_matrix(val_y, vy))\n",
    "\n",
    "print(f\"Mean f1 score oheart_diseases {np.mean(f1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1455b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_per_class = eval_metric(Y_test, test_predict, 'Accuracy:type=PerClass')\n",
    "# for cls, value in zip(clf.classes_, accuracy_per_class):\n",
    "#     print(f'Accuracy for class {cls}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61c152",
   "metadata": {},
   "source": [
    "### Приведение тестового датасета в анализируемый вид"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79addc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>family_status</th>\n",
       "      <th>ethnos</th>\n",
       "      <th>nationality</th>\n",
       "      <th>religion</th>\n",
       "      <th>education</th>\n",
       "      <th>profession</th>\n",
       "      <th>work_status</th>\n",
       "      <th>pension_age</th>\n",
       "      <th>stop_working</th>\n",
       "      <th>...</th>\n",
       "      <th>smoke_status</th>\n",
       "      <th>smoking_age</th>\n",
       "      <th>cigarettes_pd</th>\n",
       "      <th>passive_smoke</th>\n",
       "      <th>pass_smoke_rate</th>\n",
       "      <th>alcohol_status</th>\n",
       "      <th>alcohol_age</th>\n",
       "      <th>sleep_daily</th>\n",
       "      <th>sport_status</th>\n",
       "      <th>Религия, клубы</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex family_status ethnos nationality religion education profession  \\\n",
       "0   1             2      1           1        1         1          9   \n",
       "1   1             0      1           1        1         2          1   \n",
       "2   1             1      1           1        1         2          1   \n",
       "3   1             1      1           1        1         4          0   \n",
       "4   0             1      1           1        1         1          2   \n",
       "\n",
       "   work_status  pension_age  stop_working  ...  smoke_status  smoking_age  \\\n",
       "0            1            0             0  ...             0          0.0   \n",
       "1            0            1             0  ...             0          0.0   \n",
       "2            0            1             0  ...             0          0.0   \n",
       "3            1            0             0  ...             0          0.0   \n",
       "4            0            1             0  ...             1         14.0   \n",
       "\n",
       "   cigarettes_pd  passive_smoke  pass_smoke_rate  alcohol_status  alcohol_age  \\\n",
       "0            0.0              0                0               1         23.0   \n",
       "1            0.0              0                0               1         22.0   \n",
       "2            0.0              0                0               1         18.0   \n",
       "3            0.0              0                0               0          0.0   \n",
       "4           20.0              0                0               1         19.0   \n",
       "\n",
       "   sleep_daily  sport_status  Религия, клубы  \n",
       "0            0             1               1  \n",
       "1            0             0               0  \n",
       "2            0             0               0  \n",
       "3            0             0               0  \n",
       "4            0             0               0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('D:/Projects/cp_heartdetect_model/Dataset/test.csv')\n",
    "\n",
    "df_test = df_test.rename(columns=\n",
    "{'ID': 'id', \n",
    "'Пол': 'sex',\n",
    "'Семья': 'family_status',\n",
    "'Этнос': 'ethnos',\n",
    "'Национальность': 'nationality',\n",
    "'Религия': 'religion',\n",
    "'Образование': 'education',\n",
    "'Профессия': 'profession',\n",
    "'Вы работаете?': 'work_status',\n",
    "'Выход на пенсию': 'pension_age',\n",
    "'Прекращение работы по болезни': 'stop_working',\n",
    "'Сахарный диабет': 'diabetes',\n",
    "'Гепатит': 'hepatitis',\n",
    "'Онкология': 'oncology',\n",
    "'Хроническое заболевание легких': 'lung_disease',\n",
    "'Бронжиальная астма': 'bronchial_asthma',\n",
    "'Туберкулез легких ': 'tuberculosis',\n",
    "'ВИЧ/СПИД': 'HIV_AIDS',\n",
    "'Регулярный прим лекарственных средств': 'intake_medicines',\n",
    "'Травмы за год': 'injuries_per_year',\n",
    "'Переломы': 'fractures',\n",
    "'Статус Курения': 'smoke_status',\n",
    "'Возраст курения': 'smoking_age',\n",
    "'Сигарет в день': 'cigarettes_pd',\n",
    "'Пассивное курение': 'passive_smoke',\n",
    "'Частота пасс кур': 'pass_smoke_rate',\n",
    "'Алкоголь': 'alcohol_status',\n",
    "'Возраст алког': 'alcohol_age',\n",
    "'Время засыпания': 'sleep_start_time',\n",
    "'Время пробуждения': 'sleep_end_time',\n",
    "'Сон после обеда': 'sleep_daily',\n",
    "'Спорт, клубы': 'sport_status',\n",
    "'Религия,клубы': 'religion_status',\n",
    "'Артериальная гипертензия': 'arterial_hypertension',\n",
    "'ОНМК': 'insult_status',\n",
    "'Стенокардия, ИБС, инфаркт миокарда': 'infarction_status',\n",
    "'Сердечная недостаточность': 'heart_failure',\n",
    "'Прочие заболевания сердца': 'oheart_diseases',\n",
    "})\n",
    "\n",
    "# replace empty with 0\n",
    "#df_test = df_test.replace('', np.nan, regex=True)\n",
    "df_test = df_test.fillna(0)\n",
    "\n",
    "# sex 1-женщина, 0-мужчина\n",
    "df_test.replace({'sex': 'М'}, {'sex': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'sex': 'Ж'}, {'sex': '1'}, regex=True, inplace = True)\n",
    "\n",
    "# family_status: 1-в браке в настоящее время, 0-в разводе, 2-вдовец / вдова, 3-никогда не был(а) в браке, 4-гражданский брак / проживание с партнером, 5-раздельное проживание (официально не разведены)\n",
    "df_test.replace({'family_status': 'в браке в настоящее время'}, {'family_status': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'family_status': 'в разводе'}, {'family_status': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'family_status': 'вдовец / вдова'}, {'family_status': '2'}, inplace = True)\n",
    "df_test.replace({'family_status': 'никогда не был(а) в браке'}, {'family_status': '3'}, inplace = True)\n",
    "df_test.replace({'family_status': 'гражданский брак / проживание с партнером'}, {'family_status': '4'}, inplace = True)\n",
    "df_test.replace({'family_status': 'раздельное проживание (официально не разведены)'}, {'family_status': '5'}, inplace = True)\n",
    "\n",
    "# ethnos 1-европейская, 2-другая азиатская (Корея, Малайзия, Таиланд, Вьетнам, Казахстан, Киргизия, Туркмения, Узбекистан, Таджикистан)\n",
    "df_test.replace({'ethnos': 'европейская'}, {'ethnos': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'ethnos': 'другая азиатская (Корея, Малайзия, Таиланд, Вьетнам, Казахстан, Киргизия, Туркмения, Узбекистан, Таджикистан)'}, {'ethnos': '2'}, inplace = True)\n",
    "df_test.replace({'ethnos': 'прочее (любая иная этно-расовая группа, не представленная выше)'}, {'ethnos': '2'},  inplace = True)\n",
    "\n",
    "# nationality:\n",
    "# 1-'Русские' 2-'Азербайджанцы' 3-'Татары' 4-'Немцы' 5-'Эстонцы'\n",
    "# 0-'Другие национальности' 6-'Молдаване' 7-'Украинцы' 8-'Чуваши' 9-'Мордва'\n",
    "# 10-'Киргизы' 11-'Казахи' 12-'Армяне' 13-'Белорусы' 14-'Таджики' 15-'Башкиры' 16-'Евреи'\n",
    "# 17-'Буряты'\n",
    "df_test.replace({'nationality': 'Другие национальности'}, {'nationality': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Русские'}, {'nationality': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Азербайджанцы'}, {'nationality': '2'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Татары'}, {'nationality': '3'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Немцы'}, {'nationality': '4'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Эстонцы'}, {'nationality': '5'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Молдаване'}, {'nationality': '6'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Украинцы'}, {'nationality': '7'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Чуваши'}, {'nationality': '8'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Мордва'}, {'nationality': '9'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Киргизы'}, {'nationality': '10'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Казахи'}, {'nationality': '11'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Армяне'}, {'nationality': '12'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Белорусы'}, {'nationality': '13'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Таджики'}, {'nationality': '14'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Башкиры'}, {'nationality': '15'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Евреи'}, {'nationality': '16'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Буряты'}, {'nationality': '17'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Удмурты'}, {'nationality': '18'}, regex=True, inplace = True)\n",
    "df_test.replace({'nationality': 'Лезгины'}, {'nationality': '19'}, regex=True, inplace = True)\n",
    "\n",
    "# religion: 1-'Христианство' 2-'Атеист / агностик' 3-'Ислам' 0-'Нет'\n",
    "df_test.replace({'religion': 'Нет'}, {'religion': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'religion': 'Христианство'}, {'religion': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'religion': 'Атеист / агностик'}, {'religion': '2'}, regex=True, inplace = True)\n",
    "df_test.replace({'religion': 'Ислам'}, {'religion': '3'}, regex=True, inplace = True)\n",
    "df_test.replace({'religion': 'Другое'}, {'religion': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'religion': 'Индуизм'}, {'religion': '4'}, regex=True, inplace = True)\n",
    "\n",
    "# education: 1-'3 - средняя школа / закон.среднее / выше среднего' 2-'5 - ВУЗ' 3-'2 - начальная школа' 4-'4 - профессиональное училище'\n",
    "df_test.replace({'education': '3 - средняя школа / закон.среднее / выше среднего'}, {'education': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'education': '5 - ВУЗ'}, {'education': '2'}, regex=True, inplace = True)\n",
    "df_test.replace({'education': '2 - начальная школа'}, {'education': '3'}, regex=True, inplace = True)\n",
    "df_test.replace({'education': '4 - профессиональное училище'}, {'education': '4'}, regex=True, inplace = True)\n",
    "\n",
    "# profession: 0-'низкоквалифицированные работники' 1-'дипломированные специалисты'\n",
    "# 2-'операторы и монтажники установок и машинного оборудования' 3-'служащие'\n",
    "# 4-'работники,  занятые в сфере обслуживания, торговые работники магазинов и рынков'\n",
    "# 5-'представители   законодат.   органов   власти,  высокопостав. долж.лица и менеджеры'\n",
    "# 6-'техники и младшие специалисты' 7-'ведение домашнего хозяйства'\n",
    "# 8-'квалифицированные работники сельского хозяйства и рыболовного'\n",
    "# 9-'ремесленники и представители других отраслей промышленности'\n",
    "# 10-'вооруженные силы'\n",
    "df_test.replace({'profession': 'низкоквалифицированные работники'}, {'profession': '0'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'дипломированные специалисты'}, {'profession': '1'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'операторы и монтажники установок и машинного оборудования'}, {'profession': '2'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'служащие'}, {'profession': '3'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'работники,  занятые в сфере обслуживания, торговые работники магазинов и рынков'}, {'profession': '4'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'представители   законодат.   органов   власти,  высокопостав. долж.лица и менеджеры'}, {'profession': '5'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'техники и младшие специалисты'}, {'profession': '6'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'ведение домашнего хозяйства'}, {'profession': '7'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'квалифицированные работники сельского хозяйства и рыболовного'}, {'profession': '8'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'ремесленники и представители других отраслей промышленности'}, {'profession': '9'}, regex=True, inplace = True)\n",
    "df_test.replace({'profession': 'вооруженные силы'}, {'profession': '10'}, regex=True, inplace = True)\n",
    "\n",
    "# smoke_status: 1-'Курит' 0-'Никогда не курил(а)' 2-'Бросил(а)'\n",
    "df_test.replace({'smoke_status': 'Курит'}, {'smoke_status': '1'}, inplace = True)\n",
    "df_test.replace({'smoke_status': 'Никогда не курил(а)'}, {'smoke_status': '0'},  inplace = True)\n",
    "df_test.replace({'smoke_status': 'Никогда не курил'}, {'smoke_status': '0'},  inplace = True)\n",
    "df_test.replace({'smoke_status': 'Бросил(а)'}, {'smoke_status': '2'},  inplace = True)\n",
    "\n",
    "\n",
    "# pass_smoke_rate: 1-'1-2 раза в неделю' 2-'3-6 раз в неделю' 3-'не менее 1 раза в день' 4-'4 и более раз в день' 5-'2-3 раза в день'\n",
    "df_test.replace({'pass_smoke_rate': '1-2 раза в неделю'}, {'pass_smoke_rate': '1'}, inplace = True)\n",
    "df_test.replace({'pass_smoke_rate': '3-6 раз в неделю'}, {'pass_smoke_rate': '2'},  inplace = True)\n",
    "df_test.replace({'pass_smoke_rate': 'не менее 1 раза в день'}, {'pass_smoke_rate': '3'},  inplace = True)\n",
    "df_test.replace({'pass_smoke_rate': '4 и более раз в день'}, {'pass_smoke_rate': '4'},  inplace = True)\n",
    "df_test.replace({'pass_smoke_rate': '2-3 раза в день'}, {'pass_smoke_rate': '5'},  inplace = True)\n",
    "\n",
    "# alcohol_status, 1-'употребляю в настоящее время' 0-'никогда не употреблял' 2-'ранее употреблял'\n",
    "df_test.replace({'alcohol_status': 'употребляю в настоящее время'}, {'alcohol_status': '1'}, inplace = True)\n",
    "df_test.replace({'alcohol_status': 'никогда не употреблял'}, {'alcohol_status': '0'}, inplace = True)\n",
    "df_test.replace({'alcohol_status': 'ранее употреблял'}, {'alcohol_status': '2'}, inplace = True)\n",
    "\n",
    "# drop id and id_y, sleep_start_time, sleep_end_time\n",
    "columns_to_drop = ['id', 'sleep_start_time', 'sleep_end_time']\n",
    "df_test.drop(labels=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d5db093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'arterial_hypertension','insult_status','infarction_status','heart_failure','oheart_diseases'\n",
    "\n",
    "arterial_hypertension_model = arterial_hypertension.predict(df_test)\n",
    "arterial_hypertension_model\n",
    "\n",
    "insult_status_model = insult_status.predict(df_test)\n",
    "insult_status_model\n",
    "\n",
    "infarction_status_model = infarction_status.predict(df_test)\n",
    "infarction_status_model\n",
    "\n",
    "heart_failure_model = heart_failure.predict(df_test)\n",
    "heart_failure_model\n",
    "\n",
    "oheart_diseases_model = oheart_diseases.predict(df_test)\n",
    "oheart_diseases_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b7d40cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [955, 638]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-fe97dbf3338b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marterial_hypertension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1778\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1779\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1780\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1781\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1465\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1275\u001b[0m                          str(average_options))\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 320\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [955, 638]"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.recall_score(y1,arterial_hypertension.predict(df_test),average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210798c3",
   "metadata": {},
   "source": [
    "### Генерация решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11072fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Артериальная гипертензия</th>\n",
       "      <th>ОНМК</th>\n",
       "      <th>\"Стенокардия, ИБС, инфаркт миокарда\"</th>\n",
       "      <th>Сердечная недостаточность</th>\n",
       "      <th>Прочие заболевания сердца</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54-001-019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54-002-133-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54-001-007-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54-102-116-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54-502-005-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>54-102-095-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>54-102-235-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>54-502-016-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>54-002-138-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>54-103-022-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Артериальная гипертензия  ОНМК  \\\n",
       "0    54-001-019-01                         1     0   \n",
       "1    54-002-133-01                         1     0   \n",
       "2    54-001-007-01                         0     0   \n",
       "3    54-102-116-01                         0     0   \n",
       "4    54-502-005-02                         1     0   \n",
       "..             ...                       ...   ...   \n",
       "633  54-102-095-01                         1     0   \n",
       "634  54-102-235-01                         1     0   \n",
       "635  54-502-016-01                         1     0   \n",
       "636  54-002-138-01                         0     0   \n",
       "637  54-103-022-01                         1     0   \n",
       "\n",
       "     \"Стенокардия, ИБС, инфаркт миокарда\"  Сердечная недостаточность  \\\n",
       "0                                       0                          0   \n",
       "1                                       0                          0   \n",
       "2                                       0                          0   \n",
       "3                                       0                          0   \n",
       "4                                       0                          0   \n",
       "..                                    ...                        ...   \n",
       "633                                     0                          0   \n",
       "634                                     0                          0   \n",
       "635                                     0                          0   \n",
       "636                                     0                          0   \n",
       "637                                     0                          0   \n",
       "\n",
       "     Прочие заболевания сердца  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "..                         ...  \n",
       "633                          0  \n",
       "634                          0  \n",
       "635                          0  \n",
       "636                          0  \n",
       "637                          0  \n",
       "\n",
       "[638 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Артериальная гипертензия,ОНМК,\"Стенокардия, ИБС, инфаркт миокарда\",Сердечная недостаточность,Прочие заболевания сердца\n",
    "\n",
    "df_val = pd.read_csv('D:/Projects/cp_heartdetect_model/Dataset/test.csv')\n",
    "\n",
    "submission = pd.DataFrame(df_val['ID'],columns=['ID',])\n",
    "submission['Артериальная гипертензия'] = arterial_hypertension_model\n",
    "submission['ОНМК'] = insult_status_model\n",
    "submission[\"\\\"Стенокардия, ИБС, инфаркт миокарда\\\"\"] = infarction_status_model\n",
    "submission['Сердечная недостаточность'] = heart_failure_model\n",
    "submission['Прочие заболевания сердца'] = oheart_diseases_model\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19127bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Артериальная гипертензия 0    353\n",
      "1    285\n",
      "Name: Артериальная гипертензия, dtype: int64\n",
      "ОНМК 0    634\n",
      "1      4\n",
      "Name: ОНМК, dtype: int64\n",
      "\"Стенокардия, ИБС, инфаркт миокарда\" 0    628\n",
      "1     10\n",
      "Name: \"Стенокардия, ИБС, инфаркт миокарда\", dtype: int64\n",
      "Сердечная недостаточность 0    633\n",
      "1      5\n",
      "Name: Сердечная недостаточность, dtype: int64\n",
      "Прочие заболевания сердца 0    634\n",
      "1      4\n",
      "Name: Прочие заболевания сердца, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Артериальная гипертензия', submission['Артериальная гипертензия'].value_counts())\n",
    "print('ОНМК', submission['ОНМК'].value_counts())\n",
    "print('\"Стенокардия, ИБС, инфаркт миокарда\"', submission['\"Стенокардия, ИБС, инфаркт миокарда\"'].value_counts())\n",
    "print('Сердечная недостаточность', submission['Сердечная недостаточность'].value_counts())\n",
    "print('Прочие заболевания сердца', submission['Прочие заболевания сердца'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6484fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6f14f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv', 'r', encoding='utf-8') as file :\n",
    "  filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace('\"\"\"', '\"')\n",
    "\n",
    "with open('submission.csv', 'w', encoding='utf-8') as file:\n",
    "  file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b6dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0002ca97fa5ee54dc2e4008fbe9eabec60bb4400642f4fca2bafe1dfe14f90e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
